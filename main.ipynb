{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38564bit28b29d54bb434118891186d15ae7c84f",
      "display_name": "Python 3.8.5 64-bit",
      "language": "python"
    },
    "colab": {
      "name": "Copy of main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nik1806/Semantic-segmentation/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuklJ8hzEwLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9f0a4a-de19-43ba-cd7c-148532b1c5cc"
      },
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDOrGbbpFJZf"
      },
      "source": [
        "# Load the data and organizing it \n",
        "root_dir = 'drive/My Drive/'\n",
        "data_dir = root_dir + 'NN_pro_data'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPkjKXMJFVKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76b2e66-a28b-421a-a3bc-298ec47178d7"
      },
      "source": [
        "# change directory\n",
        "# import os\n",
        "# os.chdir(data_dir)\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gtFine_trainvaltest.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVWoPKwGUjD"
      },
      "source": [
        "# unzip data \n",
        "#!unzip gtFine_trainvaltest.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS1zeahaWCp2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSuaMW1rHtRr"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQD0uCZKq49"
      },
      "source": [
        "# Insert the directory - FOR importing user-defined modules/packages\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/Semantic-segmentation')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJxgW61OEosh"
      },
      "source": [
        "from dataset import cityscapes_train\n",
        "from dataset import cityscapes_val\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Cityscapes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmfX_R7nEosv"
      },
      "source": [
        "transformation = transforms.Compose([\n",
        "    #transforms.CenterCrop(100),\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# check if need of normalization"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw7FK90KEosv"
      },
      "source": [
        "# dst_train = cityscapes_train('cityscape', transform=transformation)\n",
        "# dst_val = cityscapes_val('cityscape', transform=transformation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Bm5yK9XXhKpH",
        "outputId": "a95ee46f-124f-44c2-8adc-5da88628ae5c"
      },
      "source": [
        "dst_train = Cityscapes(data_dir, split='train', mode='fine', target_type='semantic', transforms=transformation)\n",
        "dst_val = Cityscapes(data_dir, split='val', mode='fine', target_type='semantic', transforms=transformation)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d95c2eacc2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdst_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'semantic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cityscapes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, mode, target_type, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dir_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n\u001b[0m\u001b[1;32m    153\u001b[0m                                    ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or incomplete. Please make sure all required folders for the specified \"split\" and \"mode\" are inside the \"root\" directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtUHjgtXEosw"
      },
      "source": [
        "length_train = len(dst_train)\n",
        "length_val = len(dst_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5k2-POJEosw",
        "outputId": "323667a9-3464-4d9b-effa-09e990da7e01"
      },
      "source": [
        "print(length_train)\n",
        "print(length_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2975\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rkx_lfwEosx",
        "outputId": "14582b19-5bd8-48a9-ce6c-e41c0c2ab62f"
      },
      "source": [
        "dst_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1569, 0.2824, 0.3137,  ..., 0.9255, 0.8627, 0.6902],\n",
              "          [0.1451, 0.1922, 0.2549,  ..., 0.7137, 0.4667, 0.3216],\n",
              "          [0.1451, 0.2000, 0.3216,  ..., 0.3294, 0.2941, 0.2980],\n",
              "          ...,\n",
              "          [0.1647, 0.1608, 0.1608,  ..., 0.1686, 0.1686, 0.1647],\n",
              "          [0.1569, 0.1569, 0.1569,  ..., 0.1686, 0.1686, 0.1647],\n",
              "          [0.1529, 0.1529, 0.1569,  ..., 0.1686, 0.1686, 0.1647]],\n",
              " \n",
              "         [[0.2118, 0.3608, 0.4078,  ..., 1.0000, 0.9529, 0.7882],\n",
              "          [0.2000, 0.2471, 0.3137,  ..., 0.8157, 0.5569, 0.4039],\n",
              "          [0.2000, 0.2627, 0.4039,  ..., 0.4118, 0.3804, 0.3882],\n",
              "          ...,\n",
              "          [0.2157, 0.2118, 0.2118,  ..., 0.2196, 0.2235, 0.2157],\n",
              "          [0.2039, 0.2078, 0.2078,  ..., 0.2196, 0.2196, 0.2157],\n",
              "          [0.2000, 0.2000, 0.2039,  ..., 0.2235, 0.2235, 0.2157]],\n",
              " \n",
              "         [[0.1490, 0.2863, 0.3529,  ..., 0.9843, 0.9216, 0.7529],\n",
              "          [0.1333, 0.1647, 0.2510,  ..., 0.7725, 0.5255, 0.3725],\n",
              "          [0.1569, 0.1922, 0.3490,  ..., 0.3765, 0.3373, 0.3451],\n",
              "          ...,\n",
              "          [0.1804, 0.1765, 0.1765,  ..., 0.1882, 0.1922, 0.1882],\n",
              "          [0.1725, 0.1725, 0.1765,  ..., 0.1882, 0.1882, 0.1882],\n",
              "          [0.1686, 0.1686, 0.1725,  ..., 0.1882, 0.1882, 0.1882]]]),\n",
              " tensor([[[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
              "          [0.0078, 0.0078, 0.0078,  ..., 0.0118, 0.0039, 0.0039],\n",
              "          [0.0078, 0.0078, 0.0078,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS0c-WbVEosx",
        "outputId": "64048c1e-71fe-4baa-9ef2-ff1506fe01d2"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.imshow(dst_train[1][1].data.numpy().transpose((1,2,0)).squeeze(2))\n",
        "print(dst_train[1][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"251.467969pt\" version=\"1.1\" viewBox=\"0 0 257.9275 251.467969\" width=\"257.9275pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 251.467969 \nL 257.9275 251.467969 \nL 257.9275 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 227.589844 \nL 250.7275 227.589844 \nL 250.7275 10.149844 \nL 33.2875 10.149844 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p4791742c03)\">\n    <image height=\"218\" id=\"imagedddacc70c8\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"33.2875\" xlink:href=\"data:image/png;base64,\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\" y=\"-9.589844\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md69da3f7d6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.136875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(30.955625 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"68.111875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(61.749375 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"102.086875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(95.724375 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.061875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(129.699375 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.036875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(163.674375 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"204.011875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(194.468125 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.986875\" xlink:href=\"#md69da3f7d6\" y=\"227.589844\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(228.443125 242.188281)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mbc2c13703f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"44.974219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(13.5625 48.773438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"78.949219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 40 -->\n      <g transform=\"translate(13.5625 82.748437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"112.924219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 60 -->\n      <g transform=\"translate(13.5625 116.723438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"146.899219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 80 -->\n      <g transform=\"translate(13.5625 150.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"180.874219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 184.673438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mbc2c13703f\" y=\"214.849219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 120 -->\n      <g transform=\"translate(7.2 218.648438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 227.589844 \nL 33.2875 10.149844 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 250.7275 227.589844 \nL 250.7275 10.149844 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 227.589844 \nL 250.7275 227.589844 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.149844 \nL 250.7275 10.149844 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4791742c03\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"33.2875\" y=\"10.149844\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwHWIGqfEosy"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 2\n",
        "#Dataloaders\n",
        "train_loader = DataLoader(dst_train, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(dst_val, batch_size=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUGPTBncEosy"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "#print(dataiter.next())\n",
        "(images, labels) = dataiter.next()\n",
        "\n",
        "dataiter_val = iter(val_loader)\n",
        "(images_val, labels_val) = dataiter_val.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVmKFCxjEosy"
      },
      "source": [
        "from network1 import R2UNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTFTCLoEosz",
        "outputId": "bd043458-e4f5-446c-f8a3-3db8ba637d17"
      },
      "source": [
        "import torch\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\")\n",
        "model = R2UNet(in_channels=3,n_classes=34).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c4f8eb874f99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR2UNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n\u001b[1;32m    152\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vj_jdjgEosz"
      },
      "source": [
        "from torch.optim import SGD, Adam, lr_scheduler\n",
        "\n",
        "optimizer = Adam(model.parameters(), 5e-4, (0.9, 0.999),  eps=1e-08, weight_decay=1e-4) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "X9tMY3mBEosz",
        "outputId": "f14d60e7-05d5-4438-dde5-6989244bffb4"
      },
      "source": [
        "loss_train = []\n",
        "loss_val = []\n",
        "\n",
        "for epoch in range(1):\n",
        "    #Training\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    #images = dst[0:][0]\n",
        "    #labels = dst[0:][1]\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        inputs = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.squeeze(1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        #print(labels.shape)\n",
        "        #print(outputs.shape)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #loss = criterion(outputs,targets[:,0])\n",
        "        #loss = criterion(outputs,labels[:,0].long())\n",
        "        loss = criterion(outputs,labels.long())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ###accumulating loss for each batch\n",
        "        #running_loss = loss.item()*inputs.size(0)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        #if i%10 == 0:\n",
        "    #print(\"epoch{}, iter{}, loss: {}\".format(epoch, i, loss.item()))\n",
        "    loss_train.append(running_loss/len(train_loader))\n",
        "    print(\"epoch{}, loss: {}\".format(epoch, running_loss)\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    running_loss_val = 0\n",
        "    for i, (images, labels) in enumerate(val_loader):\n",
        "        inputs = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.squeeze(1)\n",
        "             \n",
        "        with torch.no_grad(): \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs,labels.long())\n",
        "\n",
        "\n",
        "        ###accumulating loss for each batch\n",
        "        running_loss_val += loss.item()\n",
        "\n",
        "        #if i%10 == 0:\n",
        "    loss_val.append(running_loss_val/len(val_loader))\n",
        "    print(\"epoch{}, loss: {}\".format(epoch, running_loss_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch0, iter0, loss: 9.64998034760356e-05\n",
            "epoch0, iter10, loss: 9.49534005485475e-05\n",
            "epoch0, iter20, loss: 0.00011086778249591589\n",
            "epoch0, iter30, loss: 0.00010876869782805443\n",
            "epoch0, iter40, loss: 0.00013484805822372437\n",
            "epoch0, iter50, loss: 8.747319225221872e-05\n",
            "epoch0, iter60, loss: 0.00013881956692785025\n",
            "epoch0, iter70, loss: 0.00010735751129686832\n",
            "epoch0, iter80, loss: 0.00010126829147338867\n",
            "epoch0, iter90, loss: 0.00013012986164540052\n",
            "epoch0, iter100, loss: 0.0001070423168130219\n",
            "epoch0, iter110, loss: 0.00010182172991335392\n",
            "epoch0, iter120, loss: 0.00010480787022970617\n",
            "epoch0, iter130, loss: 0.00011405546683818102\n",
            "epoch0, iter140, loss: 8.7750144302845e-05\n",
            "epoch0, iter150, loss: 8.219055598601699e-05\n",
            "epoch0, iter160, loss: 9.723438415676355e-05\n",
            "epoch0, iter170, loss: 9.723578114062548e-05\n",
            "epoch0, iter180, loss: 8.195685222744942e-05\n",
            "epoch0, iter190, loss: 0.00010311603546142578\n",
            "epoch0, iter200, loss: 0.00010032980935648084\n",
            "epoch0, iter210, loss: 0.00010401906911283731\n",
            "epoch0, iter220, loss: 9.258266072720289e-05\n",
            "epoch0, iter230, loss: 8.198275463655591e-05\n",
            "epoch0, iter240, loss: 0.00011015901691280305\n",
            "epoch0, iter250, loss: 9.450723882764578e-05\n",
            "epoch0, iter260, loss: 0.0001180390827357769\n",
            "epoch0, iter270, loss: 0.00010639114771038294\n",
            "epoch0, iter280, loss: 0.00010394048877060413\n",
            "epoch0, iter290, loss: 9.429157944396138e-05\n",
            "epoch0, iter300, loss: 9.166327072307467e-05\n",
            "epoch0, iter310, loss: 8.908071322366595e-05\n",
            "epoch0, iter320, loss: 8.317903848364949e-05\n",
            "epoch0, iter330, loss: 8.305796654894948e-05\n",
            "epoch0, iter340, loss: 6.858282722532749e-05\n",
            "epoch0, iter350, loss: 7.633562199771404e-05\n",
            "epoch0, iter360, loss: 8.790806168690324e-05\n",
            "epoch0, iter370, loss: 8.438201621174812e-05\n",
            "epoch0, iter380, loss: 0.00011190760415047407\n",
            "epoch0, iter390, loss: 8.795352187007666e-05\n",
            "epoch0, iter400, loss: 0.00010680919513106346\n",
            "epoch0, iter410, loss: 8.350028656423092e-05\n",
            "epoch0, iter420, loss: 8.590606739744544e-05\n",
            "epoch0, iter430, loss: 8.397799683734775e-05\n",
            "epoch0, iter440, loss: 7.246452150866389e-05\n",
            "epoch0, iter450, loss: 0.00010337107232771814\n",
            "epoch0, iter460, loss: 8.055119542405009e-05\n",
            "epoch0, iter470, loss: 7.764287875033915e-05\n",
            "epoch0, iter480, loss: 7.623893907293677e-05\n",
            "epoch0, iter490, loss: 8.963979780673981e-05\n",
            "epoch0, iter500, loss: 9.100150782614946e-05\n",
            "epoch0, iter510, loss: 9.926798520609736e-05\n",
            "epoch0, iter520, loss: 7.027620449662209e-05\n",
            "epoch0, iter530, loss: 8.277944289147854e-05\n",
            "epoch0, iter540, loss: 8.832552703097463e-05\n",
            "epoch0, iter550, loss: 7.292424561455846e-05\n",
            "epoch0, iter560, loss: 7.667491445317864e-05\n",
            "epoch0, iter570, loss: 9.798287646844983e-05\n",
            "epoch0, iter580, loss: 8.236145367845893e-05\n",
            "epoch0, iter590, loss: 7.984135299921036e-05\n",
            "epoch0, iter600, loss: 7.740152068436146e-05\n",
            "epoch0, iter610, loss: 8.110905764624476e-05\n",
            "epoch0, iter620, loss: 7.185275899246335e-05\n",
            "epoch0, iter630, loss: 7.923322846181691e-05\n",
            "epoch0, iter640, loss: 7.18499650247395e-05\n",
            "epoch0, iter650, loss: 7.255608215928078e-05\n",
            "epoch0, iter660, loss: 8.860643720254302e-05\n",
            "epoch0, iter670, loss: 9.468750795349479e-05\n",
            "epoch0, iter680, loss: 5.673401756212115e-05\n",
            "epoch0, iter690, loss: 7.962097879499197e-05\n",
            "epoch0, iter700, loss: 7.930758874863386e-05\n",
            "epoch0, iter710, loss: 6.679620128124952e-05\n",
            "epoch0, iter720, loss: 6.48766290396452e-05\n",
            "epoch0, iter730, loss: 7.106020348146558e-05\n",
            "epoch0, iter740, loss: 8.04880983196199e-05\n",
            "epoch0, iter750, loss: 6.787903839722276e-05\n",
            "epoch0, iter760, loss: 6.92052417434752e-05\n",
            "epoch0, iter770, loss: 6.830785423517227e-05\n",
            "epoch0, iter780, loss: 7.777096470817924e-05\n",
            "epoch0, iter790, loss: 7.598905358463526e-05\n",
            "epoch0, iter800, loss: 7.849914254620671e-05\n",
            "epoch0, iter810, loss: 8.088175673037767e-05\n",
            "epoch0, iter820, loss: 6.769178435206413e-05\n",
            "epoch0, iter830, loss: 7.376627763733268e-05\n",
            "epoch0, iter840, loss: 6.041390588507056e-05\n",
            "epoch0, iter850, loss: 6.26088585704565e-05\n",
            "epoch0, iter860, loss: 7.563235703855753e-05\n",
            "epoch0, iter870, loss: 7.001485209912062e-05\n",
            "epoch0, iter880, loss: 9.18263103812933e-05\n",
            "epoch0, iter890, loss: 7.901497883722186e-05\n",
            "epoch0, iter900, loss: 7.461366476491094e-05\n",
            "epoch0, iter910, loss: 7.34244822524488e-05\n",
            "epoch0, iter920, loss: 6.634151213802397e-05\n",
            "epoch0, iter930, loss: 0.00018592010019347072\n",
            "epoch0, iter940, loss: 0.0002671270922292024\n",
            "epoch0, iter950, loss: 0.00012253402383066714\n",
            "epoch0, iter960, loss: 0.0001350336242467165\n",
            "epoch0, iter970, loss: 9.53782582655549e-05\n",
            "epoch0, iter980, loss: 8.001551032066345e-05\n",
            "epoch0, iter990, loss: 0.00010463088983669877\n",
            "epoch0, iter1000, loss: 0.00010826188372448087\n",
            "epoch0, iter1010, loss: 9.558530291542411e-05\n",
            "epoch0, iter1020, loss: 7.054180605337024e-05\n",
            "epoch0, iter1030, loss: 0.00010869663674384356\n",
            "epoch0, iter1040, loss: 9.671068983152509e-05\n",
            "epoch0, iter1050, loss: 7.549632573500276e-05\n",
            "epoch0, iter1060, loss: 7.520039798691869e-05\n",
            "epoch0, iter1070, loss: 5.67592796869576e-05\n",
            "epoch0, iter1080, loss: 8.601963054388762e-05\n",
            "epoch0, iter1090, loss: 6.866420153528452e-05\n",
            "epoch0, iter1100, loss: 7.502856897190213e-05\n",
            "epoch0, iter1110, loss: 7.578160148113966e-05\n",
            "epoch0, iter1120, loss: 8.14022496342659e-05\n",
            "epoch0, iter1130, loss: 6.598402978852391e-05\n",
            "epoch0, iter1140, loss: 6.783055141568184e-05\n",
            "epoch0, iter1150, loss: 6.790750194340944e-05\n",
            "epoch0, iter1160, loss: 7.455842569470406e-05\n",
            "epoch0, iter1170, loss: 8.099398110061884e-05\n",
            "epoch0, iter1180, loss: 6.653112359344959e-05\n",
            "epoch0, iter1190, loss: 7.340667070820928e-05\n",
            "epoch0, iter1200, loss: 6.430211942642927e-05\n",
            "epoch0, iter1210, loss: 7.644231664016843e-05\n",
            "epoch0, iter1220, loss: 6.948009831830859e-05\n",
            "epoch0, iter1230, loss: 7.233105134218931e-05\n",
            "epoch0, iter1240, loss: 7.163803093135357e-05\n",
            "epoch0, iter1250, loss: 5.861144745722413e-05\n",
            "epoch0, iter1260, loss: 7.094541797414422e-05\n",
            "epoch0, iter1270, loss: 7.309915963560343e-05\n",
            "epoch0, iter1280, loss: 5.563226295635104e-05\n",
            "epoch0, iter1290, loss: 5.64238871447742e-05\n",
            "epoch0, iter1300, loss: 7.060531061142683e-05\n",
            "epoch0, iter1310, loss: 7.270340574905276e-05\n",
            "epoch0, iter1320, loss: 7.060350617393851e-05\n",
            "epoch0, iter1330, loss: 5.04753552377224e-05\n",
            "epoch0, iter1340, loss: 6.546243093907833e-05\n",
            "epoch0, iter1350, loss: 6.512808613479137e-05\n",
            "epoch0, iter1360, loss: 6.503774784505367e-05\n",
            "epoch0, iter1370, loss: 6.329925963655114e-05\n",
            "epoch0, iter1380, loss: 6.307486910372972e-05\n",
            "epoch0, iter1390, loss: 6.217736518010497e-05\n",
            "epoch0, iter1400, loss: 6.729061715304852e-05\n",
            "epoch0, iter1410, loss: 6.261869566515088e-05\n",
            "epoch0, iter1420, loss: 8.168804924935102e-05\n",
            "epoch0, iter1430, loss: 6.637221667915583e-05\n",
            "epoch0, iter1440, loss: 5.505559965968132e-05\n",
            "epoch0, iter1450, loss: 6.814929656684399e-05\n",
            "epoch0, iter1460, loss: 6.368430331349373e-05\n",
            "epoch0, iter1470, loss: 6.42788945697248e-05\n",
            "epoch0, iter1480, loss: 7.876468589529395e-05\n",
            "epoch0, iter1490, loss: 5.9160985983908176e-05\n",
            "epoch0, iter1500, loss: 6.162823410704732e-05\n",
            "epoch0, iter1510, loss: 6.772496271878481e-05\n",
            "epoch0, iter1520, loss: 6.011215737089515e-05\n",
            "epoch0, iter1530, loss: 5.113915540277958e-05\n",
            "epoch0, iter1540, loss: 6.09478447586298e-05\n",
            "epoch0, iter1550, loss: 8.53565288707614e-05\n",
            "epoch0, iter1560, loss: 7.487734546884894e-05\n",
            "epoch0, iter1570, loss: 6.828468758612871e-05\n",
            "epoch0, iter1580, loss: 6.412691436707973e-05\n",
            "epoch0, iter1590, loss: 7.805100176483393e-05\n",
            "epoch0, iter1600, loss: 7.564609404653311e-05\n",
            "epoch0, iter1610, loss: 7.394026033580303e-05\n",
            "epoch0, iter1620, loss: 7.04193371348083e-05\n",
            "epoch0, iter1630, loss: 8.025794522836804e-05\n",
            "epoch0, iter1640, loss: 6.847584154456854e-05\n",
            "epoch0, iter1650, loss: 7.202697452157736e-05\n",
            "epoch0, iter1660, loss: 7.214379729703069e-05\n",
            "epoch0, iter1670, loss: 6.721954559907317e-05\n",
            "epoch0, iter1680, loss: 5.813664756715298e-05\n",
            "epoch0, iter1690, loss: 7.83322611823678e-05\n",
            "epoch0, iter1700, loss: 6.779056275263429e-05\n",
            "epoch0, iter1710, loss: 6.769888568669558e-05\n",
            "epoch0, iter1720, loss: 7.959251524880528e-05\n",
            "epoch0, iter1730, loss: 6.462825695052743e-05\n",
            "epoch0, iter1740, loss: 6.815738743171096e-05\n",
            "epoch0, iter1750, loss: 6.848783232271671e-05\n",
            "epoch0, iter1760, loss: 6.145820952951908e-05\n",
            "epoch0, iter1770, loss: 6.08462723903358e-05\n",
            "epoch0, iter1780, loss: 9.771157056093216e-05\n",
            "epoch0, iter1790, loss: 5.8887992054224014e-05\n",
            "epoch0, iter1800, loss: 6.735202623531222e-05\n",
            "epoch0, iter1810, loss: 6.0143356677144766e-05\n",
            "epoch0, iter1820, loss: 6.842444417998195e-05\n",
            "epoch0, iter1830, loss: 6.815418601036072e-05\n",
            "epoch0, iter1840, loss: 7.252889918163419e-05\n",
            "epoch0, iter1850, loss: 7.177423685789108e-05\n",
            "epoch0, iter1860, loss: 6.501341704279184e-05\n",
            "epoch0, iter1870, loss: 7.523008389398456e-05\n",
            "epoch0, iter1880, loss: 8.39384738355875e-05\n",
            "epoch0, iter1890, loss: 7.500645006075501e-05\n",
            "epoch0, iter1900, loss: 7.789622759446502e-05\n",
            "epoch0, iter1910, loss: 6.725237471982837e-05\n",
            "epoch0, iter1920, loss: 8.702219929546118e-05\n",
            "epoch0, iter1930, loss: 7.734302198514342e-05\n",
            "epoch0, iter1940, loss: 6.913836114108562e-05\n",
            "epoch0, iter1950, loss: 6.411405047401786e-05\n",
            "epoch0, iter1960, loss: 5.85914240218699e-05\n",
            "epoch0, iter1970, loss: 7.127353455871344e-05\n",
            "epoch0, iter1980, loss: 6.283627590164542e-05\n",
            "epoch0, iter1990, loss: 6.893568206578493e-05\n",
            "epoch0, iter2000, loss: 6.821646820753813e-05\n",
            "epoch0, iter2010, loss: 7.164647104218602e-05\n",
            "epoch0, iter2020, loss: 6.489042425528169e-05\n",
            "epoch0, iter2030, loss: 9.269372094422579e-05\n",
            "epoch0, iter2040, loss: 8.495297515764832e-05\n",
            "epoch0, iter2050, loss: 6.135134026408195e-05\n",
            "epoch0, iter2060, loss: 6.449059583246708e-05\n",
            "epoch0, iter2070, loss: 6.411218782886863e-05\n",
            "epoch0, iter2080, loss: 6.520148599520326e-05\n",
            "epoch0, iter2090, loss: 6.297649815678596e-05\n",
            "epoch0, iter2100, loss: 7.306470070034266e-05\n",
            "epoch0, iter2110, loss: 6.886298069730401e-05\n",
            "epoch0, iter2120, loss: 6.273301551118493e-05\n",
            "epoch0, iter2130, loss: 6.349716568365693e-05\n",
            "epoch0, iter2140, loss: 7.649336475878954e-05\n",
            "epoch0, iter2150, loss: 7.252092473208904e-05\n",
            "epoch0, iter2160, loss: 6.188551196828485e-05\n",
            "epoch0, iter2170, loss: 6.888405187055469e-05\n",
            "epoch0, iter2180, loss: 6.556988228112459e-05\n",
            "epoch0, iter2190, loss: 7.790629751980305e-05\n",
            "epoch0, iter2200, loss: 6.142689380794764e-05\n",
            "epoch0, iter2210, loss: 6.588990800082684e-05\n",
            "epoch0, iter2220, loss: 7.911416469141841e-05\n",
            "epoch0, iter2230, loss: 7.128686411306262e-05\n",
            "epoch0, iter2240, loss: 7.560034282505512e-05\n",
            "epoch0, iter2250, loss: 6.280560046434402e-05\n",
            "epoch0, iter2260, loss: 7.85414595156908e-05\n",
            "epoch0, iter2270, loss: 8.028448792174459e-05\n",
            "epoch0, iter2280, loss: 8.008576696738601e-05\n",
            "epoch0, iter2290, loss: 6.439682329073548e-05\n",
            "epoch0, iter2300, loss: 9.296770440414548e-05\n",
            "epoch0, iter2310, loss: 8.58873245306313e-05\n",
            "epoch0, iter2320, loss: 7.487734546884894e-05\n",
            "epoch0, iter2330, loss: 7.009413093328476e-05\n",
            "epoch0, iter2340, loss: 8.382875239476562e-05\n",
            "epoch0, iter2350, loss: 7.415126310661435e-05\n",
            "epoch0, iter2360, loss: 8.3768623881042e-05\n",
            "epoch0, iter2370, loss: 6.039207801222801e-05\n",
            "epoch0, iter2380, loss: 6.249744910746813e-05\n",
            "epoch0, iter2390, loss: 7.499830098822713e-05\n",
            "epoch0, iter2400, loss: 6.063329055905342e-05\n",
            "epoch0, iter2410, loss: 6.760237738490105e-05\n",
            "epoch0, iter2420, loss: 6.845657480880618e-05\n",
            "epoch0, iter2430, loss: 9.458063868805766e-05\n",
            "epoch0, iter2440, loss: 8.93424148671329e-05\n",
            "epoch0, iter2450, loss: 7.19497911632061e-05\n",
            "epoch0, iter2460, loss: 8.7964057456702e-05\n",
            "epoch0, iter2470, loss: 7.525738328695297e-05\n",
            "epoch0, iter2480, loss: 7.53413769416511e-05\n",
            "epoch0, iter2490, loss: 7.98480468802154e-05\n",
            "epoch0, iter2500, loss: 5.227752262726426e-05\n",
            "epoch0, iter2510, loss: 6.706739077344537e-05\n",
            "epoch0, iter2520, loss: 7.351976819336414e-05\n",
            "epoch0, iter2530, loss: 7.062830263748765e-05\n",
            "epoch0, iter2540, loss: 8.463847916573286e-05\n",
            "epoch0, iter2550, loss: 8.996500400826335e-05\n",
            "epoch0, iter2560, loss: 7.005245424807072e-05\n",
            "epoch0, iter2570, loss: 5.6373130064457655e-05\n",
            "epoch0, iter2580, loss: 7.173162885010242e-05\n",
            "epoch0, iter2590, loss: 6.557558663189411e-05\n",
            "epoch0, iter2600, loss: 6.452074740082026e-05\n",
            "epoch0, iter2610, loss: 7.751391967758536e-05\n",
            "epoch0, iter2620, loss: 6.232154555618763e-05\n",
            "epoch0, iter2630, loss: 7.49367754906416e-05\n",
            "epoch0, iter2640, loss: 7.665640441700816e-05\n",
            "epoch0, iter2650, loss: 7.028027903288603e-05\n",
            "epoch0, iter2660, loss: 6.337149534374475e-05\n",
            "epoch0, iter2670, loss: 7.83395953476429e-05\n",
            "epoch0, iter2680, loss: 5.722965579479933e-05\n",
            "epoch0, iter2690, loss: 8.083297871053219e-05\n",
            "epoch0, iter2700, loss: 7.402797928079963e-05\n",
            "epoch0, iter2710, loss: 9.145447984337807e-05\n",
            "epoch0, iter2720, loss: 7.930537685751915e-05\n",
            "epoch0, iter2730, loss: 8.712802082300186e-05\n",
            "epoch0, iter2740, loss: 8.63070017658174e-05\n",
            "epoch0, iter2750, loss: 7.246033055707812e-05\n",
            "epoch0, iter2760, loss: 8.601153967902064e-05\n",
            "epoch0, iter2770, loss: 8.443003753200173e-05\n",
            "epoch0, iter2780, loss: 6.125739309936762e-05\n",
            "epoch0, iter2790, loss: 7.083499804139137e-05\n",
            "epoch0, iter2800, loss: 6.916502024978399e-05\n",
            "epoch0, iter2810, loss: 7.524382090196013e-05\n",
            "epoch0, iter2820, loss: 6.812898209318519e-05\n",
            "epoch0, iter2830, loss: 7.527810521423817e-05\n",
            "epoch0, iter2840, loss: 6.341090193018317e-05\n",
            "epoch0, iter2850, loss: 6.951694376766682e-05\n",
            "epoch0, iter2860, loss: 7.20764510333538e-05\n",
            "epoch0, iter2870, loss: 7.7863282058388e-05\n",
            "epoch0, iter2880, loss: 0.00011652905959635973\n",
            "epoch0, iter2890, loss: 0.0001362645416520536\n",
            "epoch0, iter2900, loss: 9.873573435470462e-05\n",
            "epoch0, iter2910, loss: 8.21102294139564e-05\n",
            "epoch0, iter2920, loss: 8.007988799363375e-05\n",
            "epoch0, iter2930, loss: 9.13094263523817e-05\n",
            "epoch0, iter2940, loss: 8.424354018643498e-05\n",
            "epoch0, iter2950, loss: 8.066918235272169e-05\n",
            "epoch0, iter2960, loss: 8.132413495332003e-05\n",
            "epoch0, iter2970, loss: 6.310408934950829e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O26vshFlEos0",
        "outputId": "409ca9b6-012c-4735-d682-f5e74a7afee6"
      },
      "source": [
        "x = [i for i in range(len(train_loader))]\n",
        "\n",
        "pyplot.title(\"Plot showing training and validation loss against number of epochs\")\n",
        "pyplot.xlabel(\"Number of epochs\")\n",
        "pyplot.ylabel(\"Loss\")\n",
        "pyplot.plot(x, loss_train, color='r', label='training loss')\n",
        "    \n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "pyplot.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (0,) and (2975,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a176767075dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2789\u001b[0m         is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \"\"\"\n\u001b[1;32m   1664\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    270\u001b[0m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (0,) and (2975,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJJsiFQhEos1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}