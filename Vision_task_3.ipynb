{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short description about attempt/idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import Cityscapes\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.custom_transforms import unNormalize, decode_segmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory path\n",
    "data_dir = '../datasets/cityscapes/'\n",
    "base_size = 256\n",
    "crop_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 train images\n"
     ]
    }
   ],
   "source": [
    "# dataset readers\n",
    "dst_train = cityscapes.CityscapesSegmentation(crop_size, base_size, root=data_dir, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 val images\n"
     ]
    }
   ],
   "source": [
    "dst_val = cityscapes.CityscapesSegmentation(crop_size, base_size, root=data_dir, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32 # 16\n",
    "cls_num = 19\n",
    "#Dataloaders\n",
    "train_loader = DataLoader(dst_train, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(dst_val, batch_size=bs,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.networkT3 import DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/zhanghang1989/ResNeSt/archive/master.zip\" to /home/nipa00002/.cache/torch/hub/master.zip\n",
      "Using cache found in /home/nipa00002/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    }
   ],
   "source": [
    "model = DeepLab(num_classes=cls_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "lr = 3e-4\n",
    "wdk = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, lr_scheduler\n",
    "criterion = torch.nn.CrossEntropyLoss(size_average=True, ignore_index=255)\n",
    "optimizer = Adam(model.parameters(), lr, (0.9, 0.999),  eps=1e-08, weight_decay=wdk) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, running loss: 0.10421179234981537\n",
      "epoch0, iter60, running loss: 0.02633669868600173\n",
      "epoch0, Training loss: 0.7234590293899659\n",
      "epoch0, Validation loss: 0.39705962128937244\n",
      "epoch1, iter0, running loss: 0.016666030511260033\n",
      "epoch1, iter60, running loss: 0.013339264593163475\n",
      "epoch1, Training loss: 0.419252194704548\n",
      "epoch1, Validation loss: 0.3995732497423887\n",
      "epoch2, iter0, running loss: 0.01224917359650135\n",
      "epoch2, iter60, running loss: 0.012573738063334441\n",
      "epoch2, Training loss: 0.3959495082337369\n",
      "epoch2, Validation loss: 0.3207666287198663\n",
      "epoch3, iter0, running loss: 0.010324180126190186\n",
      "epoch3, iter60, running loss: 0.01130299305268487\n",
      "epoch3, Training loss: 0.35965030840648116\n",
      "epoch3, Validation loss: 0.2917316844686866\n",
      "epoch4, iter0, running loss: 0.010269450955092907\n",
      "epoch4, iter60, running loss: 0.010483105346316197\n",
      "epoch4, Training loss: 0.3285475969314575\n",
      "epoch4, Validation loss: 0.28152393735945225\n",
      "epoch5, iter0, running loss: 0.008283833973109722\n",
      "epoch5, iter60, running loss: 0.009605539519889433\n",
      "epoch5, Training loss: 0.3151486913363139\n",
      "epoch5, Validation loss: 0.28467908315360546\n",
      "epoch6, iter0, running loss: 0.008858856745064259\n",
      "epoch6, iter60, running loss: 0.00983372797853634\n",
      "epoch6, Training loss: 0.31414228036839476\n",
      "epoch6, Validation loss: 0.2810384016484022\n",
      "epoch7, iter0, running loss: 0.009664688259363174\n",
      "epoch7, iter60, running loss: 0.009356256963715691\n",
      "epoch7, Training loss: 0.3036632353580126\n",
      "epoch7, Validation loss: 0.26412807311862707\n",
      "epoch8, iter0, running loss: 0.008427178487181664\n",
      "epoch8, iter60, running loss: 0.009810394523512633\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Training\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for i, samples in enumerate(train_loader):\n",
    "        inputs = samples['image'].to(device)\n",
    "        labels = samples['label'].to(device).long()\n",
    "        # labels = labels.squeeze(1\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ###accumulating loss for each batch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i%60 == 0:\n",
    "            print(\"epoch{}, iter{}, running loss: {}\".format(epoch, i, running_loss/(bs*(i+1))))\n",
    "                  \n",
    "    loss_train.append(running_loss/len(train_loader))\n",
    "\n",
    "    print(\"epoch{}, Training loss: {}\".format(epoch, running_loss/len(train_loader)))\n",
    "    torch.save(model.state_dict(), f'../weights/T3/epoch_{epoch}.pth')\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    running_loss_val = 0\n",
    "    for i, samples in enumerate(val_loader):\n",
    "        inputs = samples['image'].to(device)\n",
    "        labels = samples['label'].to(device).long()\n",
    "        # labels = labels.squeeze(1)\n",
    "             \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(inputs)\n",
    "            # loss = criterion(outputs,labels.long())\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            ###accumulating loss for each batch\n",
    "            running_loss_val += loss.item()\n",
    "\n",
    "\n",
    "        #if i%10 == 0:\n",
    "    loss_val.append(running_loss_val/len(val_loader))\n",
    "    print(\"epoch{}, Validation loss: {}\".format(epoch, running_loss_val/len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curves\n",
    "x = range(epochs)\n",
    "plt.title(\"Plot showing training and validation loss against number of epochs\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, loss_train, color='b', label='Training loss')\n",
    "plt.plot(x, loss_val, color='r', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('results/T3_loss_curves.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epochs=1\n",
    "# move model to gpu\n",
    "model = model.to(device)\n",
    "# load the model states\n",
    "model.load_state_dict(torch.load(f'../weights/T3/epoch_{epochs-1}.pth'))\n",
    "\n",
    "# model in evaluation model -> batchnorm, dropout etc. adjusted accordingly\n",
    "model.eval()\n",
    "# iterator on training data\n",
    "data = iter(train_loader)\n",
    "# init figure object\n",
    "fig = plt.figure(figsize=(10,40))\n",
    "pred_rgb = list()\n",
    "# for img, label in trainloader:\n",
    "for i in range(10):\n",
    "    sample = next(data) # next batch\n",
    "    imgs, labels = sample['image'], sample['label']\n",
    "    # img, label = img.to(device).unsqueeze(0), label.to(device) # to gpu\n",
    "    # using just one image\n",
    "    img = imgs[0].to(device).unsqueeze(0) # to gpu & add dummy batch dim\n",
    "    # gnd = np.asarray(label[0]) \n",
    "    # deactivate autograd engine - reduce memory usage \n",
    "    with torch.no_grad(): \n",
    "        pred = model(img) # forward pass\n",
    "        # output of model is orderedDict\n",
    "#         pred = pred['out'] # 21(class)xHxW\n",
    "        pred = pred.squeeze(0)\n",
    "        \n",
    "        # extract most probable class through C-dim \n",
    "        pred_label = torch.argmax(pred, dim=0).cpu().numpy()\n",
    "        # convert labels to color code\n",
    "#         pred_rgb = dst_train.decode_segmap(pred_label)\n",
    "        pred_rgb = decode_segmap(pred_label, nc=cls_num, dataset='cityscapes')\n",
    "\n",
    "        # plotting\n",
    "        # original image\n",
    "        fig.add_subplot(10, 3, 3*i+1)\n",
    "        img = imgs[0].data.cpu().numpy() # data in image and current form of matrix\n",
    "        img = unNormalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # unNormalize\n",
    "        img = img.transpose((1,2,0)).astype(np.uint8) # change dtype to correct format for display\n",
    "        plt.title('Original')\n",
    "        plt.imshow(img) # original\n",
    "        plt.axis('off')\n",
    "        # ground truth\n",
    "        fig.add_subplot(10, 3, 3*i+2)\n",
    "        label = labels[0].data.numpy() # data in image and current form of matrix\n",
    "        label = decode_segmap(label, nc=cls_num, dataset='cityscapes')\n",
    "#         label = dst_train.decode_segmap(label)\n",
    "        plt.title('Ground truth')\n",
    "        plt.imshow(label) \n",
    "        plt.axis('off')\n",
    "        # prediction\n",
    "        fig.add_subplot(10, 3, 3*i+3)\n",
    "        plt.title('Prediction')\n",
    "        plt.imshow(pred_rgb.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.savefig('results/T3 results.png', bbox_inches='tight')    \n",
    "plt.plot()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 evaluation matrices to be used: sensitivity, specificity, accuracy, AUC, and DC\n",
    "from utils.eval_metrics import dice_coefficient_custom, roc_auc_custom, accuracy_se_sp_custom, sensitivity_custom, specificity_custom# user defined\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "def evaluate_batch(gnd_b, pred_b, cls:int = 34):\n",
    "    \"\"\"\n",
    "        Calculate evalution scores over the batch.\n",
    "    Args:   \n",
    "        gnd_b: BxHxW tensor; ground truth labels; each element of matrix in B dim contains class label from (0-20)\n",
    "        pred_b: BxCxHxW tensor; each element contains predicted class label \n",
    "                here C=21 (0-20; no. of classes); each C corresponds to probabilites for that class,\n",
    "                eg. C=0 contain score at each element in matrix HxW \n",
    "    Return:\n",
    "        f1_score, auc_score, dice_coeeficient (averaged over batch size)\n",
    "    \"\"\"\n",
    "    # to cpu and as numpy ndarray\n",
    "    gnd_b = gnd_b.cpu()\n",
    "\n",
    "    batch_size = gnd_b.shape[0]\n",
    "    \n",
    "    # extract most probable class through C-dim \n",
    "    label_b = torch.argmax(pred_b, dim=1).cpu()\n",
    "    sensitivity = specificity = accuracy = auc = dice = 0\n",
    "    # iterate over batch elements\n",
    "    for i in range(batch_size):\n",
    "        gnd = gnd_b[i,:,:] \n",
    "        label = label_b[i,:,:]\n",
    "        #f1 += f1_score(gnd.flatten(), label.flatten(), average='micro')\n",
    "        #sensitivity += sensitivity_custom(gnd, label)\n",
    "        \n",
    "        \n",
    "        #specificity += specificity_custom(gnd, label)\n",
    "        #accuracy += accuracy_se_sp_custom(gnd, label)\n",
    "        temp = accuracy_se_sp_custom(gnd, label)\n",
    "        accuracy += temp[0]\n",
    "        sensitivity += temp[1]\n",
    "        specificity += temp[2]\n",
    "        # auc += roc_auc_score(gnd.flatten(), label.flatten(), average='micro', multi_class='ovr')\n",
    "        auc += roc_auc_custom(gnd.numpy(), label.numpy(), cls, average='micro')\n",
    "        dice += dice_coefficient_custom(gnd.numpy(), label.numpy(), cls)\n",
    "\n",
    "    return [sensitivity/batch_size, specificity/batch_size, accuracy/batch_size, auc/batch_size, dice/batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of score \n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "auc_list = []\n",
    "dice_list = []\n",
    "\n",
    "# For print\n",
    "print('Epochs\\t Sensitivity-score Specificity-score Accuracy-score ROC-AUC-score\\t Dice score')\n",
    "\n",
    "# move model to gpu\n",
    "model = model.to(device)\n",
    "# loop for original number of epochs\n",
    "for i in range(epochs):\n",
    "    # load the model states\n",
    "    model.load_state_dict(torch.load(f'../weights/T3/epoch_{i}.pth'))\n",
    "    # model in evaluation model -> batchnorm, dropout etc. adjusted accordingly\n",
    "    model.eval()\n",
    "    # evaluation score variables to store values over each epoch\n",
    "    sensitivity_score = specificity_score = accuracy_score = auc_score = dice_score = 0\n",
    "\n",
    "\n",
    "    for sample in val_loader:\n",
    "        img, label = sample['image'].to(device), sample['label'].to(device)\n",
    "#         img, label = img.to(device), label.to(device) # to gpu\n",
    "        # deactivate autograd engine - reduce memory usage \n",
    "        with torch.no_grad(): \n",
    "            pred = model(img) # forward pass\n",
    "            # output of model is orderedDict\n",
    "#             pred = pred['out'] # Batchx21(class)xHxW\n",
    "            # evaluation\n",
    "            scores = evaluate_batch(label, pred, cls=cls_num)\n",
    "            # sum values\n",
    "            sensitivity_score += scores[0]\n",
    "            specificity_score += scores[1]\n",
    "            accuracy_score += scores[2]\n",
    "            auc_score += scores[3]\n",
    "            dice_score += scores[4]\n",
    "\n",
    "    print('{}\\t {:.3f}\\t\\t\\t {:.3f}\\t\\t {:.3f}\\t\\t {:.3f}\\t\\t {:.3f}'.format(i ,sensitivity_score/len(val_loader), specificity_score/len(val_loader), accuracy_score/len(val_loader), auc_score/len(val_loader), dice_score/len(val_loader)))\n",
    "    # append to list (with averaged values over valid set)\n",
    "    sensitivity_list.append(sensitivity_score/len(val_loader))\n",
    "    specificity_list.append(specificity_score/len(val_loader))\n",
    "    accuracy_list.append(accuracy_score/len(val_loader))\n",
    "    auc_list.append(auc_score/len(val_loader))\n",
    "    dice_list.append(dice_score/len(val_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "X = range(1, epochs+1)\n",
    "plt.plot(X, sensitivity_list, label=\"sensitivity-score\")\n",
    "plt.plot(X, specificity_list, label=\"specificity-score\")\n",
    "plt.plot(X, accuracy_list, label=\"accuracy-score\")\n",
    "plt.plot(X, auc_list, label=\"AUC-ROC score\")\n",
    "plt.plot(X, dice_list, label=\"Dice coefficient\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Evaluation metrics score\")\n",
    "plt.title(\"Performance evalaution\")\n",
    "plt.legend() # add legend\n",
    "plt.savefig('results/T3_eval_metrics.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
