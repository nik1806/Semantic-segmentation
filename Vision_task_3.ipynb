{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short description about attempt/idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# from datasets.custom_transforms import unNormalize, decode_segmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory path\n",
    "data_dir = '../datasets/cityscapes/'\n",
    "# for augmentation\n",
    "base_size = 288 # original image resize to 'base_size' dim\n",
    "crop_size = 256 # finally a random crop is performed and image of 'crop_size' dim is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 train images\n"
     ]
    }
   ],
   "source": [
    "# dataset readers\n",
    "# additional augmentations are defined inside the reader\n",
    "dst_train = cityscapes.CityscapesSegmentation(crop_size, base_size, root=data_dir, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 val images\n"
     ]
    }
   ],
   "source": [
    "dst_val = cityscapes.CityscapesSegmentation(crop_size, base_size, root=data_dir, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 42 # maximum possible with image resolution, model size and available\n",
    "cls_num = 19 # ignoring rare classes which cause class imbalance problem\n",
    "#Dataloaders\n",
    "train_loader = DataLoader(dst_train, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(dst_val, batch_size=bs,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from models.networkT3 import DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which gpu to use\n",
    "device = torch.device(\"cuda:5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/zhanghang1989/ResNeSt/archive/master.zip\" to /home/nipa00002/.cache/torch/hub/master.zip\n",
      "Using cache found in /home/nipa00002/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    }
   ],
   "source": [
    "# create instance of model\n",
    "model = DeepLab(num_classes=cls_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "lr = 3e-4\n",
    "mlr = 1e-2\n",
    "wdk = 4e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, lr_scheduler\n",
    "# loss function\n",
    "criterion = torch.nn.CrossEntropyLoss(size_average=True, ignore_index=255) # 255 label assigned to ignored classes\n",
    "# optimizer\n",
    "optimizer = Adam(model.parameters(), mlr, (0.9, 0.999),  eps=1e-08, weight_decay=wdk)\n",
    "# learning rate scheduler (update after every batch)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=mlr, steps_per_epoch=len(train_loader), epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, running loss: 0.0875198103132702\n",
      "epoch0, iter60, running loss: 0.025418779516852896\n",
      "epoch0, Training loss: 1.0104147103470815\n",
      "epoch0, Validation loss: 0.5039363900820414\n",
      "epoch1, iter0, running loss: 0.015480277084168933\n",
      "epoch1, iter60, running loss: 0.013011586831287888\n",
      "epoch1, Training loss: 0.5381001477510157\n",
      "epoch1, Validation loss: 0.4015345300237338\n",
      "epoch2, iter0, running loss: 0.012902746597925821\n",
      "epoch2, iter60, running loss: 0.011956190627873828\n",
      "epoch2, Training loss: 0.5027136202429382\n",
      "epoch2, Validation loss: 0.4096009110411008\n",
      "epoch3, iter0, running loss: 0.008635501776422774\n",
      "epoch3, iter60, running loss: 0.010848553035521675\n",
      "epoch3, Training loss: 0.45839822670103797\n",
      "epoch3, Validation loss: 0.3794664020339648\n",
      "epoch4, iter0, running loss: 0.010832515500840686\n",
      "epoch4, iter60, running loss: 0.01031121504576666\n",
      "epoch4, Training loss: 0.42810890036569516\n",
      "epoch4, Validation loss: 0.3664625957608223\n",
      "epoch5, iter0, running loss: 0.010929280803317116\n",
      "epoch5, iter60, running loss: 0.011083420764460032\n",
      "epoch5, Training loss: 0.4670491785230771\n",
      "epoch5, Validation loss: 0.48319947471221286\n",
      "epoch6, iter0, running loss: 0.013441531431107294\n",
      "epoch6, iter60, running loss: 0.010990789586170682\n",
      "epoch6, Training loss: 0.464931157693057\n",
      "epoch6, Validation loss: 0.5353731835881869\n",
      "epoch7, iter0, running loss: 0.011101992357344855\n",
      "epoch7, iter60, running loss: 0.01178009748738041\n",
      "epoch7, Training loss: 0.4936706935855704\n",
      "epoch7, Validation loss: 0.43027909596761066\n",
      "epoch8, iter0, running loss: 0.011123382619449071\n",
      "epoch8, iter60, running loss: 0.011226469236458772\n",
      "epoch8, Training loss: 0.46827033875693735\n",
      "epoch8, Validation loss: 0.4187810942530632\n",
      "epoch9, iter0, running loss: 0.010331989753813971\n",
      "epoch9, iter60, running loss: 0.011892056448863503\n",
      "epoch9, Training loss: 0.5000145792121619\n",
      "epoch9, Validation loss: 0.5440071622530619\n",
      "epoch10, iter0, running loss: 0.011254653334617615\n",
      "epoch10, iter60, running loss: 0.011682136230036954\n",
      "epoch10, Training loss: 0.4871956941107629\n",
      "epoch10, Validation loss: 0.5263969153165817\n",
      "epoch11, iter0, running loss: 0.012879746300833566\n",
      "epoch11, iter60, running loss: 0.011919069718235085\n",
      "epoch11, Training loss: 0.5030373897351009\n",
      "epoch11, Validation loss: 0.41302941491206485\n",
      "epoch12, iter0, running loss: 0.011412568035579863\n",
      "epoch12, iter60, running loss: 0.010767869005716935\n",
      "epoch12, Training loss: 0.4564235050913314\n",
      "epoch12, Validation loss: 0.49383407086133957\n",
      "epoch13, iter0, running loss: 0.01103761721225012\n",
      "epoch13, iter60, running loss: 0.010796426703090504\n",
      "epoch13, Training loss: 0.46070301112994344\n",
      "epoch13, Validation loss: 0.8390689392884573\n",
      "epoch14, iter0, running loss: 0.010176182502791994\n",
      "epoch14, iter60, running loss: 0.011865046413311448\n",
      "epoch14, Training loss: 0.5032580381547901\n",
      "epoch14, Validation loss: 1.1585393448670704\n",
      "epoch15, iter0, running loss: 0.0116839295341855\n",
      "epoch15, iter60, running loss: 0.012071767407502168\n",
      "epoch15, Training loss: 0.5020742235888898\n",
      "epoch15, Validation loss: 0.45591021080811817\n",
      "epoch16, iter0, running loss: 0.0099003818773088\n",
      "epoch16, iter60, running loss: 0.011153730584903213\n",
      "epoch16, Training loss: 0.4642173299487208\n",
      "epoch16, Validation loss: 0.8044809599717458\n",
      "epoch17, iter0, running loss: 0.011022923248154777\n",
      "epoch17, iter60, running loss: 0.011454120999570008\n",
      "epoch17, Training loss: 0.47575073384902844\n",
      "epoch17, Validation loss: 0.4195927456021309\n",
      "epoch18, iter0, running loss: 0.010241793025107611\n",
      "epoch18, iter60, running loss: 0.010741858895079965\n",
      "epoch18, Training loss: 0.4516952230896748\n",
      "epoch18, Validation loss: 0.3755155752102534\n",
      "epoch19, iter0, running loss: 0.009952062652224586\n",
      "epoch19, iter60, running loss: 0.011092134977485126\n",
      "epoch19, Training loss: 0.46384709695695153\n",
      "epoch19, Validation loss: 0.42484115312496823\n",
      "epoch20, iter0, running loss: 0.011966403041567122\n",
      "epoch20, iter60, running loss: 0.01056347761788841\n",
      "epoch20, Training loss: 0.4420879819023777\n",
      "epoch20, Validation loss: 0.8064520955085754\n",
      "epoch21, iter0, running loss: 0.010980468420755295\n",
      "epoch21, iter60, running loss: 0.0101326500806466\n",
      "epoch21, Training loss: 0.4282701771024247\n",
      "epoch21, Validation loss: 0.38998081535100937\n",
      "epoch22, iter0, running loss: 0.010123843948046366\n",
      "epoch22, iter60, running loss: 0.010811553580234239\n",
      "epoch22, Training loss: 0.4512211478931803\n",
      "epoch22, Validation loss: 0.4836147526899974\n",
      "epoch23, iter0, running loss: 0.009849800950004942\n",
      "epoch23, iter60, running loss: 0.009616591077033288\n",
      "epoch23, Training loss: 0.41044068504387227\n",
      "epoch23, Validation loss: 0.4172162984808286\n",
      "epoch24, iter0, running loss: 0.010391548985526675\n",
      "epoch24, iter60, running loss: 0.010434442635256272\n",
      "epoch24, Training loss: 0.437457714282291\n",
      "epoch24, Validation loss: 0.4477493440111478\n",
      "epoch25, iter0, running loss: 0.009209780465988885\n",
      "epoch25, iter60, running loss: 0.010463574382125354\n",
      "epoch25, Training loss: 0.4351398059180085\n",
      "epoch25, Validation loss: 0.46201615780591965\n",
      "epoch26, iter0, running loss: 0.009744297890436081\n",
      "epoch26, iter60, running loss: 0.011038381091604746\n",
      "epoch26, Training loss: 0.4565207467112743\n",
      "epoch26, Validation loss: 0.366518959403038\n",
      "epoch27, iter0, running loss: 0.010239546497662863\n",
      "epoch27, iter60, running loss: 0.009496915710335313\n",
      "epoch27, Training loss: 0.40439115359749594\n",
      "epoch27, Validation loss: 0.4674583276112874\n",
      "epoch28, iter0, running loss: 0.009289037613641648\n",
      "epoch28, iter60, running loss: 0.010153257060479039\n",
      "epoch28, Training loss: 0.426739364442691\n",
      "epoch28, Validation loss: 0.9906686246395111\n",
      "epoch29, iter0, running loss: 0.013455556971686227\n",
      "epoch29, iter60, running loss: 0.01067520660594699\n",
      "epoch29, Training loss: 0.4384647272002529\n",
      "epoch29, Validation loss: 0.3516157642006874\n",
      "epoch30, iter0, running loss: 0.008960511003221785\n",
      "epoch30, iter60, running loss: 0.009509173212434796\n"
     ]
    }
   ],
   "source": [
    "from utils.learn import train_val_loop\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "# perform loops\n",
    "loss_train, loss_val = train_val_loop(model, epochs, train_loader, val_loader, optimizer, \n",
    "                                      criterion, loss_train, 3, bs, device, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curves\n",
    "x = range(epochs)\n",
    "plt.title(\"Plot showing training and validation loss against number of epochs\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, loss_train, color='b', label='Training loss')\n",
    "plt.plot(x, loss_val, color='r', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('results/T3_loss_curves.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visual_results import visualize\n",
    "# epochs=1\n",
    "# move model to gpu\n",
    "model = model.to(device)\n",
    "# load the model states\n",
    "model.load_state_dict(torch.load(f'../weights/T3/epoch_{epochs-1}.pth'))\n",
    "# perform visualization\n",
    "visualize(model, train_loader, 'results/T3 results.png', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_metrics import evaluation_loop\n",
    "\n",
    "# #6 evaluation matrices to be used: sensitivity, specificity, accuracy, AUC, DC and IOU\n",
    "evaluation_loop(model, val_loader, epochs, device, task=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "df_r = pd.read_csv('results/T3_eval.csv')\n",
    "\n",
    "X = range(1, len(df_r)+1)\n",
    "plt.plot(X, df_r.sensitivity, label=\"sensitivity-score\")\n",
    "plt.plot(X, df_r.specificity, label=\"specificity-score\")\n",
    "plt.plot(X, df_r.accuracy, label=\"accuracy-score\")\n",
    "plt.plot(X, df_r.auc, label=\"AUC-ROC score\")\n",
    "plt.plot(X, df_r.dice, label=\"Dice coefficient\")\n",
    "plt.plot(X, df_r.iou, label=\"IOU-Jaccard\")\n",
    "\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Evaluation metrics score\")\n",
    "plt.title(\"Performance evalaution\")\n",
    "plt.legend() # add legend\n",
    "plt.savefig('results/T3_eval_metrics.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
