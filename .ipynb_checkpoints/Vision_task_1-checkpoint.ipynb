{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nik1806/Semantic-segmentation/blob/master/Vision_task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqryU0Zkgr2L"
   },
   "source": [
    "# Image Segmentation Task 1\n",
    "#### Welcome to the first task of Image Segmentation. Image segmentation is the process of partitioning the image into a set of pixels representing an object. In this task, you will be introduced to the problem of image segmentation and programming pipeline involved in image segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuWYYCszgr2j"
   },
   "source": [
    "For the purpose of this task we will be using PASCAL VOC datset. The dataset contains a total of 2913 images with segmentation annotations. Code in the cell below will download the code and extract the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zM_t4c-S3k31",
    "outputId": "993a5f16-03f5-4db5-f058-c9421e38d022",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "# !tar -xvf VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lvs9XIpBaI0",
    "outputId": "046f45e4-c235-4255-8694-978b4c8b08d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.3-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.0.8)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.19.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (50.3.1.post20201107)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.7.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-7.6.3 jupyterlab-widgets-1.0.0 widgetsnbextension-3.5.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install scipy==1.1.0\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggF1hZ6Vgr2n"
   },
   "source": [
    "### 1.1 Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qunDv45j24Mg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "import collections\n",
    "import json\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import scipy.misc as m\n",
    "import scipy.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# from PIL import Image\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class pascalVOCDataset(data.Dataset):\n",
    "    \"\"\"Data loader for the Pascal VOC semantic segmentation dataset.\n",
    "\n",
    "    Annotations from both the original VOC data (which consist of RGB images\n",
    "    in which colours map to specific classes) and the SBD (Berkely) dataset\n",
    "    (where annotations are stored as .mat files) are converted into a common\n",
    "    `label_mask` format.  Under this format, each mask is an (M,N) array of\n",
    "    integer values from 0 to 21, where 0 represents the background class.\n",
    "\n",
    "    The label masks are stored in a new folder, called `pre_encoded`, which\n",
    "    is added as a subdirectory of the `SegmentationClass` folder in the\n",
    "    original Pascal VOC data layout.\n",
    "\n",
    "    A total of five data splits are provided for working with the VOC data:\n",
    "        train: The original VOC 2012 training data - 1464 images\n",
    "        val: The original VOC 2012 validation data - 1449 images\n",
    "        trainval: The combination of `train` and `val` - 2913 images\n",
    "        train_aug: The unique images present in both the train split and\n",
    "                   training images from SBD: - 8829 images (the unique members\n",
    "                   of the result of combining lists of length 1464 and 8498)\n",
    "        train_aug_val: The original VOC 2012 validation data minus the images\n",
    "                   present in `train_aug` (This is done with the same logic as\n",
    "                   the validation set used in FCN PAMI paper, but with VOC 2012\n",
    "                   rather than VOC 2011) - 904 images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        sbd_path=None,\n",
    "        split=\"train_aug\",\n",
    "        is_transform=False,\n",
    "        img_size=512,\n",
    "        augmentations=None,\n",
    "        img_norm=True,\n",
    "        test_mode=False,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.sbd_path = sbd_path\n",
    "        self.split = split\n",
    "        self.is_transform = is_transform\n",
    "        self.augmentations = augmentations\n",
    "        self.img_norm = img_norm\n",
    "        self.test_mode = test_mode\n",
    "        self.n_classes = 21\n",
    "        self.mean = np.array([104.00699, 116.66877, 122.67892])\n",
    "        self.files = collections.defaultdict(list)\n",
    "        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n",
    "\n",
    "        if not self.test_mode:\n",
    "            for split in [\"train\", \"val\", \"trainval\"]:\n",
    "                path = pjoin(self.root, \"ImageSets/Segmentation\", split + \".txt\")\n",
    "                file_list = tuple(open(path, \"r\"))\n",
    "                file_list = [id_.rstrip() for id_ in file_list]\n",
    "                self.files[split] = file_list\n",
    "            self.setup_annotations()\n",
    "\n",
    "        self.tf = transforms.Compose(\n",
    "            [\n",
    "                # add more trasnformations as you see fit\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_name = self.files[self.split][index]\n",
    "        im_path = pjoin(self.root, \"JPEGImages\", im_name + \".jpg\")\n",
    "        lbl_path = pjoin(self.root, \"SegmentationClass/pre_encoded\", im_name + \".png\")\n",
    "        im = PIL.Image.open(im_path)\n",
    "        lbl = PIL.Image.open(lbl_path)\n",
    "        if self.augmentations is not None:\n",
    "            im, lbl = self.augmentations(im, lbl)\n",
    "        if self.is_transform:\n",
    "            im, lbl = self.transform(im, lbl)\n",
    "        return im, torch.clamp(lbl, max=20)\n",
    "\n",
    "    def transform(self, img, lbl):\n",
    "        if self.img_size == (\"same\", \"same\"):\n",
    "            pass\n",
    "        else:\n",
    "            img = img.resize((self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n",
    "            lbl = lbl.resize((self.img_size[0], self.img_size[1]))\n",
    "        img = self.tf(img)\n",
    "        lbl = torch.from_numpy(np.array(lbl)).long()\n",
    "        lbl[lbl == 255] = 0\n",
    "        return img, lbl\n",
    "\n",
    "    def get_pascal_labels(self):\n",
    "        \"\"\"Load the mapping that associates pascal classes with label colors\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray with dimensions (21, 3)\n",
    "        \"\"\"\n",
    "        return np.asarray(\n",
    "            [\n",
    "                [0, 0, 0],\n",
    "                [128, 0, 0],\n",
    "                [0, 128, 0],\n",
    "                [128, 128, 0],\n",
    "                [0, 0, 128],\n",
    "                [128, 0, 128],\n",
    "                [0, 128, 128],\n",
    "                [128, 128, 128],\n",
    "                [64, 0, 0],\n",
    "                [192, 0, 0],\n",
    "                [64, 128, 0],\n",
    "                [192, 128, 0],\n",
    "                [64, 0, 128],\n",
    "                [192, 0, 128],\n",
    "                [64, 128, 128],\n",
    "                [192, 128, 128],\n",
    "                [0, 64, 0],\n",
    "                [128, 64, 0],\n",
    "                [0, 192, 0],\n",
    "                [128, 192, 0],\n",
    "                [0, 64, 128],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def encode_segmap(self, mask):\n",
    "        \"\"\"Encode segmentation label images as pascal classes\n",
    "\n",
    "        Args:\n",
    "            mask (np.ndarray): raw segmentation label image of dimension\n",
    "              (M, N, 3), in which the Pascal classes are encoded as colours.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray): class map with dimensions (M,N), where the value at\n",
    "            a given location is the integer denoting the class index.\n",
    "        \"\"\"\n",
    "        mask = mask.astype(int)\n",
    "        label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int16)\n",
    "        for ii, label in enumerate(self.get_pascal_labels()):\n",
    "            label_mask[np.where(np.all(mask == label, axis=-1))[:2]] = ii\n",
    "        label_mask = label_mask.astype(int)\n",
    "        # print(np.unique(label_mask))\n",
    "        return label_mask\n",
    "\n",
    "    def decode_segmap(self, label_mask, plot=False):\n",
    "        \"\"\"Decode segmentation class labels into a color image\n",
    "\n",
    "        Args:\n",
    "            label_mask (np.ndarray): an (M,N) array of integer values denoting\n",
    "              the class label at each spatial location.\n",
    "            plot (bool, optional): whether to show the resulting color image\n",
    "              in a figure.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray, optional): the resulting decoded color image.\n",
    "        \"\"\"\n",
    "        label_colours = self.get_pascal_labels()\n",
    "        r = label_mask.copy()\n",
    "        g = label_mask.copy()\n",
    "        b = label_mask.copy()\n",
    "        for ll in range(0, self.n_classes):\n",
    "            r[label_mask == ll] = label_colours[ll, 0]\n",
    "            g[label_mask == ll] = label_colours[ll, 1]\n",
    "            b[label_mask == ll] = label_colours[ll, 2]\n",
    "        rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))\n",
    "        rgb[:, :, 0] = r / 255.0\n",
    "        rgb[:, :, 1] = g / 255.0\n",
    "        rgb[:, :, 2] = b / 255.0\n",
    "        if plot:\n",
    "            plt.imshow(rgb)\n",
    "            plt.show()\n",
    "        else:\n",
    "            return rgb\n",
    "\n",
    "    def setup_annotations(self):\n",
    "        \"\"\"Sets up Berkley annotations by adding image indices to the\n",
    "        `train_aug` split and pre-encode all segmentation labels into the\n",
    "        common label_mask format (if this has not already been done). This\n",
    "        function also defines the `train_aug` and `train_aug_val` data splits\n",
    "        according to the description in the class docstring\n",
    "        \"\"\"\n",
    "        sbd_path = self.sbd_path\n",
    "        target_path = pjoin(self.root, \"SegmentationClass/pre_encoded\")\n",
    "        if not os.path.exists(target_path):\n",
    "            os.makedirs(target_path)\n",
    "        train_aug = self.files[\"train\"]\n",
    "\n",
    "        # keep unique elements (stable)\n",
    "        train_aug = [train_aug[i] for i in sorted(np.unique(train_aug, return_index=True)[1])]\n",
    "        self.files[\"train_aug\"] = train_aug\n",
    "        set_diff = set(self.files[\"val\"]) - set(train_aug)  # remove overlap\n",
    "        self.files[\"train_aug_val\"] = list(set_diff)\n",
    "\n",
    "        pre_encoded = glob.glob(pjoin(target_path, \"*.png\"))\n",
    "        expected = np.unique(self.files[\"train_aug\"] + self.files[\"val\"]).size\n",
    "\n",
    "        if len(pre_encoded) != expected:\n",
    "            print(\"Pre-encoding segmentation masks...\")\n",
    "\n",
    "            for ii in tqdm(self.files[\"trainval\"]):\n",
    "                fname = ii + \".png\"\n",
    "                lbl_path = pjoin(self.root, \"SegmentationClass\", fname)\n",
    "                lbl = self.encode_segmap(m.imread(lbl_path))\n",
    "                lbl = m.toimage(lbl, high=lbl.max(), low=lbl.min())\n",
    "                m.imsave(pjoin(target_path, fname), lbl)\n",
    "\n",
    "        assert expected == 2913, \"unexpected dataset sizes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O34skJ8pgr2u"
   },
   "source": [
    "### 1.2 Define the model architecture(2.0 point)\n",
    "In this section you have the freedom to decide your own model. Keep in mind though, to perform image segmentation, you need to implement an architecture that does pixel level classification i.e. for each pixel in the image you need to predict the probability of it belonging to one of the 21 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CatAsvH3GTXs"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import segmentation\n",
    "\n",
    "class Segnet(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    \"\"\"\n",
    "      Using fully-convolutional network with resnet101 as backbone. FCN are very successful in segmentation tasks (SUPPORT BY PAPER)\n",
    "      We use pretrained layers on COCO dataset here, it will improve the performace and train faster with less data (advantages of transfer       learning).\n",
    "    \"\"\"\n",
    "    super(Segnet, self).__init__()\n",
    "    #define the layers for your model\n",
    "    self.fcn = segmentation.fcn_resnet101(pretrained=True)\n",
    "    \n",
    "\n",
    "  def forward(self, x):\n",
    "    #define the forward pass\n",
    "    out = self.fcn(x)\n",
    "    return out \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157,
     "referenced_widgets": [
      "6dc48abab91f41e38a03efc97fc88f5a",
      "b69f7c47a904498986d106e1bf36d926",
      "b4e581c1ceb9408790f30b96cff73f99",
      "ba09c1085fa74be4a05eced774156f7a",
      "b5680358c1e74addbddab3e381c36019",
      "58c5855440754107a3706f941d83e0f4",
      "e4d9fd672c704905a9a13c7d930dbad8",
      "d506f02006a648639ab6619118be8db1",
      "e91dacd227004bfbb066cd835e22afd3",
      "8560f77e7d414d4ba09d847a451df0e0",
      "0f8ff8022dae4990b1ea432b2e9d3c07",
      "92a04383007146e9b74ad6b15bc80413",
      "1d3610da2df64773b16b18f02fb4501a",
      "f0858d6174ed4af7b49a103e61536b04",
      "13ea534c6ce64663ad8e4202a002f51d",
      "bf9892dfa56c4cd6ae37fb8318044378"
     ]
    },
    "id": "QfQiOnEkGZat",
    "outputId": "547d08dc-de8c-4b40-ea30-5f362983f31f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to /home/nipa00002/.cache/torch/hub/checkpoints/fcn_resnet101_coco-7ecb50ca.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0021aa45096649d0942df0502a3dc917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=217800805.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the model defined above. \n",
    "# You can modify it incase you need to pass paratemers to the constructor.\n",
    "model = Segnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A6-PRU9gr2y"
   },
   "source": [
    "### 1.3 Hyperparameters(0.5 points)\n",
    "Define all the hyperparameters(not restricted to the three given below) that you find useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BgeL0Al7gr2y"
   },
   "outputs": [],
   "source": [
    "local_path = '../datasets/VOCdevkit/VOC2012/' # modify it according to your device\n",
    "# local_path = 'VOCdevkit/VOC2012/' # modify it according to your device\n",
    "bs = 16 # test with 16, 32 and 64 (select the best)\n",
    "epochs = 5 #5 # till 50 (5, 10, ...) (base on time also)\n",
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXVHz5f7gr2z"
   },
   "source": [
    "### 1.4 Dataset and Dataloader(0.5 points)\n",
    "Create the dataset using pascalVOCDataset class defined above. Use local_path defined in the cell above as root. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_kJoNiXgr2z",
    "outputId": "4319942b-d3bf-431e-83e2-87523811bcc7"
   },
   "outputs": [],
   "source": [
    "# dataset variable\n",
    "dst_train = pascalVOCDataset(root=local_path, is_transform=True,img_size=256, split='train') # ADD AUGMENTATION\n",
    "dst_valid = pascalVOCDataset(root=local_path, is_transform=True,img_size=256, split='val')\n",
    "\n",
    "# dataloader variable\n",
    "# using in-built dataloader with reshuffling data at each epoch\n",
    "trainloader = data.DataLoader(dst_train, batch_size=bs, shuffle=True)\n",
    "validloader = data.DataLoader(dst_valid, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display pre-encoding\n",
    "from IPython.display import Image\n",
    "Image(filename='../datasets/VOCdevkit/VOC2012/SegmentationClass/pre_encoded/2007_000733.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnRC5XrLgr2z"
   },
   "source": [
    "### 1.5 Loss fuction and Optimizer(1.0 point)\n",
    "Define below with the loss function you think would be most suitable for segmentation task. You are free to choose any optimizer to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QgxxPYOsgr20"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# loss function\n",
    "# the problem is a classification problem (into 21 classes) CrossEntropyLoss works well in this case \n",
    "loss_f = nn.CrossEntropyLoss() \n",
    "\n",
    "# optimizer variable\n",
    "# Adam contains both momentum and rmsprop feature, it works well in general\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIbBCUnvgr20"
   },
   "source": [
    "### 1.6 Training the model(3.0 points)\n",
    "Your task here is to complete the code below to perform a training loop and save the model weights after each epoch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for gpu\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:4')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "# move model\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xz08hSdPKODm",
    "outputId": "c4e35c4f-1d25-4778-963c-1a9978d4e324",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 0.1820148378610611\n",
      "epoch0, iter40, loss: 0.012384595653041444\n",
      "epoch0, iter80, loss: 0.00626926556753494\n",
      "Epoch 0: training loss=0.08831669014791813\n",
      "Epoch 0: validation loss=1.3782669496892025e-05\n",
      "epoch1, iter0, loss: 7.428069466186571e-07\n",
      "epoch1, iter40, loss: 9.476479407367595e-07\n",
      "epoch1, iter80, loss: 8.583967777903362e-07\n",
      "Epoch 1: training loss=1.3283895876394007e-05\n",
      "Epoch 1: validation loss=1.0142432199575193e-05\n",
      "epoch2, iter0, loss: 7.846215339668561e-07\n",
      "epoch2, iter40, loss: 6.69141004935937e-07\n",
      "epoch2, iter80, loss: 6.633580060673764e-07\n",
      "Epoch 2: training loss=1.0628737453296946e-05\n",
      "Epoch 2: validation loss=9.805901414778078e-06\n",
      "epoch3, iter0, loss: 5.511643621503026e-07\n",
      "epoch3, iter40, loss: 6.177383968905615e-07\n",
      "epoch3, iter80, loss: 5.83719564996567e-07\n",
      "Epoch 3: training loss=9.191262719191993e-06\n",
      "Epoch 3: validation loss=6.750801351170214e-06\n",
      "epoch4, iter0, loss: 4.11607629757782e-07\n",
      "epoch4, iter40, loss: 5.185843264837054e-07\n",
      "epoch4, iter80, loss: 4.819814237489032e-07\n",
      "Epoch 4: training loss=7.63803066784812e-06\n",
      "Epoch 4: validation loss=6.3848976254291135e-06\n"
     ]
    }
   ],
   "source": [
    "# save losses in lists\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # putting model in training mode\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for j, (img, label) in enumerate(trainloader):\n",
    "        # transfer to gpu if available for faster computation\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        # clean previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass through model\n",
    "        pred = model(img)\n",
    "        pred = pred['out'] # output of model is orderedDict\n",
    "        # loss\n",
    "        loss = loss_f(pred, label)\n",
    "        total_loss += loss.item()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # gradient descent -> update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j%40 == 0:\n",
    "            print(\"epoch{}, iter{}, loss: {}\".format(e, j, total_loss/(bs*(j+1))))\n",
    "\n",
    "    # print training loss -> later print after epoch or half epoch (costly operation)\n",
    "    print(f'Epoch {e}: training loss={total_loss/len(trainloader)}')\n",
    "    loss_train.append(total_loss/len(trainloader))\n",
    "\n",
    "    # saving model weights\n",
    "    torch.save(model.state_dict(), f'weights/T1/epoch_{e}.pth')\n",
    "\n",
    "    # validation mode - batchnorm and dropout will working val mode\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    for (img, label) in validloader:\n",
    "        img, label = img.to(device), label.to(device) # to gpu\n",
    "        # deactivate autograd engine - reduce memory usage \n",
    "        with torch.no_grad(): \n",
    "            pred = model(img) # forward pass\n",
    "            pred = pred['out'] # output of model is orderedDict\n",
    "            loss = loss_f(pred, label) # loss calc\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {e}: validation loss={valid_loss/len(validloader)}')\n",
    "    loss_val.append(valid_loss/len(validloader))\n",
    "\n",
    "\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss curves\n",
    "X = range(epochs)\n",
    "plt.plot(X, loss_train, label=\"Training loss\")\n",
    "plt.plot(X, loss_val, label=\"Validation loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss curves\")\n",
    "plt.legend() # add legend\n",
    "plt.savefig('results/T1_loss_curves.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghWL_sQ6gr21"
   },
   "source": [
    "### 1.7 Evaluate your model(1.5 points)\n",
    "In this section you have to implement the evaluation metrics for your model. Calculate the values of F1-score, dice coefficient and AUC-ROC score on the data you used for training. You can use external packages like scikit-learn to compute above metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xqYnTMNbgr21"
   },
   "outputs": [],
   "source": [
    "# import functions\n",
    "from sklearn.metrics import f1_score\n",
    "from utils.eval_metrics import dice_coefficient_custom, roc_auc_custom # user defined\n",
    "\n",
    "# def evaluate(ground_truth, predictions):\n",
    "#     \"\"\"\n",
    "#         Return evalution scores.\n",
    "#     Args:   \n",
    "#         ground_truth: HxW ndarray; each element contains class label from (0-20)\n",
    "#         prediction: HxW ndarray; each element contains predicted class label\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # calculate metrics globally (considering all false positives, true positives, false negatives and )\n",
    "#     f1 = f1_score(ground_truth, predictions, average='micro') \n",
    "#     auc_score = roc_auc_score(ground_truth, predictions, average='micro', multi_class='ovr')\n",
    "#     dice_coeeficient = 0\n",
    "\n",
    "#     return f1, auc_score, dice_coeeficient\n",
    "\n",
    "def evaluate_batch(gnd_b, pred_b):\n",
    "    \"\"\"\n",
    "        Calculate evalution scores over the batch.\n",
    "    Args:   \n",
    "        gnd_b: BxHxW tensor; ground truth labels; each element of matrix in B dim contains class label from (0-20)\n",
    "        pred_b: BxCxHxW tensor; each element contains predicted class label \n",
    "                here C=21 (0-20; no. of classes); each C corresponds to probabilites for that class,\n",
    "                eg. C=0 contain score at each element in matrix HxW \n",
    "    Return:\n",
    "        f1_score, auc_score, dice_coeeficient (averaged over batch size)\n",
    "    \"\"\"\n",
    "    # to cpu and as numpy ndarray\n",
    "    gnd_b = gnd_b.cpu().numpy()\n",
    "\n",
    "    batch_size = gnd_b.shape[0]\n",
    "    \n",
    "    # extract most probable class through C-dim \n",
    "    label_b = torch.argmax(pred_b, dim=1).cpu().numpy()\n",
    "\n",
    "    # initial value\n",
    "    f1 = auc = dice = 0\n",
    "    # iterate over batch elements\n",
    "    for i in range(batch_size):\n",
    "        gnd = gnd_b[i,:,:] \n",
    "        label = label_b[i,:,:]\n",
    "        f1 += f1_score(gnd.flatten(), label.flatten(), average='micro')\n",
    "        # auc += roc_auc_score(gnd.flatten(), label.flatten(), average='micro', multi_class='ovr')\n",
    "        auc += roc_auc_custom(gnd, label)\n",
    "        dice += dice_coefficient_custom(gnd, label)\n",
    "\n",
    "    return [f1/batch_size, auc/batch_size, dice/batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUf8J_s-gr21"
   },
   "source": [
    "### 1.8 Plot the evaluation metrics against epochs(1.0)\n",
    "In section 1.6 we saved the weights of the model after each epoch. In this section, you have to calculate the evaluation metrics after each epoch of training by loading the weights for each epoch. Once you have calculated the evaluation metrics for each epoch, plot them against the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fE2LNXlvgr21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.0 0.0 92.0\n",
      "92.0 0.0 92.0\n",
      "92.0 0.0 92.0\n",
      "92.0 0.0 92.0\n",
      "92.0 0.0 92.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list of score \n",
    "f1_list = []; auc_list = []; dice_list = []\n",
    "# move model to gpu\n",
    "model = model.to(device)\n",
    "# loop for original number of epochs\n",
    "for i in range(epochs):\n",
    "    # load the model states\n",
    "    model.load_state_dict(torch.load(f'weights/T1/epoch_{i}.pth'))\n",
    "    # model in evaluation model -> batchnorm, dropout etc. adjusted accordingly\n",
    "    model.eval()\n",
    "    # evaluation score variables to store values over each epoch\n",
    "    f_one = roc_auc = dice_coef = 0 \n",
    "\n",
    "    for img, label in trainloader:\n",
    "        img, label = img.to(device), label.to(device) # to gpu\n",
    "        # deactivate autograd engine - reduce memory usage \n",
    "        with torch.no_grad(): \n",
    "            pred = model(img) # forward pass\n",
    "            # output of model is orderedDict\n",
    "            pred = pred['out'] # Batchx21(class)xHxW\n",
    "            # evaluation\n",
    "            scores = evaluate_batch(label, pred)\n",
    "            # sum values\n",
    "            f_one += scores[0]\n",
    "            roc_auc += scores[1]\n",
    "            dice_coef += scores[2]\n",
    "    \n",
    "        # break\n",
    "\n",
    "    print(f_one, roc_auc, dice_coef)\n",
    "    # append to list (with averaged values over valid set)\n",
    "    f1_list.append(f_one/len(trainloader))\n",
    "    auc_list.append(roc_auc/len(trainloader))\n",
    "    dice_list.append(dice_coef/len(trainloader))\n",
    "\n",
    "# PLOT\n",
    "X = range(epochs)\n",
    "plt.plot(X, f1_list, label=\"F1-score\")\n",
    "plt.plot(X, auc_list, label=\"AUC-ROC score\")\n",
    "plt.plot(X, dice_list, label=\"Dice coefficient\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Evaluation metrics score\")\n",
    "plt.title(\"Performance evalaution\")\n",
    "plt.legend() # add legend\n",
    "plt.savefig('results/T1_eval_metrics.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noSVRRkjgr22"
   },
   "source": [
    "### 1.9 Visualize results(0.5 points)\n",
    "For any 10 images in the dataset, show the images along the with their segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3NS50IL_c7Mf"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 15.90 GiB total capacity; 217.66 MiB already allocated; 12.75 MiB free; 230.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a3a70d8ff491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# deactivate autograd engine - reduce memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# output of model is orderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 21(class)xHxW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bf4e98eb59af>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#define the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/segmentation/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# contract: features is a dict of tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    746\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2031\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2033\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2034\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 15.90 GiB total capacity; 217.66 MiB already allocated; 12.75 MiB free; 230.00 MiB reserved in total by PyTorch)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.custom_transforms import unNormalize, decode_segmap\n",
    "# load the model states\n",
    "# model.load_state_dict(torch.load(f'weights/T1/epoch_{epochs-1}.pth'))\n",
    "# model in evaluation model -> batchnorm, dropout etc. adjusted accordingly\n",
    "model.eval()\n",
    "# iterator on training data\n",
    "data = iter(trainloader)\n",
    "# init figure object\n",
    "fig = plt.figure(figsize=(10,40))\n",
    "pred_rgb = list()\n",
    "# for img, label in trainloader:\n",
    "for i in range(10):\n",
    "    imgs, labels = next(data) # next batch\n",
    "    # img, label = img.to(device).unsqueeze(0), label.to(device) # to gpu\n",
    "    # using just one image\n",
    "    img = imgs[0].to(device).unsqueeze(0) # to gpu\n",
    "    # gnd = np.asarray(label[0]) \n",
    "    # deactivate autograd engine - reduce memory usage \n",
    "    with torch.no_grad(): \n",
    "        pred = model(img) # forward pass\n",
    "        # output of model is orderedDict\n",
    "        pred = pred['out'].squeeze(0) # 21(class)xHxW\n",
    "        \n",
    "        # extract most probable class through C-dim \n",
    "        pred_label = torch.argmax(pred, dim=0).cpu().numpy()\n",
    "        # convert labels to color code\n",
    "        # pred_rgb = dst_train.decode_segmap(pred_label)\n",
    "        pred_rgb = decode_segmap(pred_label)\n",
    "\n",
    "        # plotting\n",
    "        # original image\n",
    "        fig.add_subplot(10, 3, 3*i+1)\n",
    "        img = imgs[0].data.cpu().numpy() # data in image and current form of matrix\n",
    "        img = unNormalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # unNormalize\n",
    "        img = img.transpose((1,2,0)).astype(np.uint8) # change dtype to correct format for display\n",
    "        plt.title('Original')\n",
    "        plt.imshow(img) # original\n",
    "        plt.axis('off')\n",
    "        # ground truth\n",
    "        fig.add_subplot(10, 3, 3*i+2)\n",
    "        label = labels[0].data.numpy() # data in image and current form of matrix\n",
    "        label = dst_train.decode_segmap(label)\n",
    "        plt.title('Ground truth')\n",
    "        plt.imshow(label) \n",
    "        plt.axis('off')\n",
    "        # prediction\n",
    "        fig.add_subplot(10, 3, 3*i+3)\n",
    "        plt.title('Prediction')\n",
    "        plt.imshow(pred_rgb.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.savefig('results/T1 results.png', bbox_inches='tight')    \n",
    "plt.plot()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of segmentation_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f8ff8022dae4990b1ea432b2e9d3c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0858d6174ed4af7b49a103e61536b04",
      "max": 217800805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d3610da2df64773b16b18f02fb4501a",
      "value": 217800805
     }
    },
    "13ea534c6ce64663ad8e4202a002f51d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d3610da2df64773b16b18f02fb4501a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "58c5855440754107a3706f941d83e0f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc48abab91f41e38a03efc97fc88f5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4e581c1ceb9408790f30b96cff73f99",
       "IPY_MODEL_ba09c1085fa74be4a05eced774156f7a"
      ],
      "layout": "IPY_MODEL_b69f7c47a904498986d106e1bf36d926"
     }
    },
    "8560f77e7d414d4ba09d847a451df0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a04383007146e9b74ad6b15bc80413": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf9892dfa56c4cd6ae37fb8318044378",
      "placeholder": "​",
      "style": "IPY_MODEL_13ea534c6ce64663ad8e4202a002f51d",
      "value": " 208M/208M [00:02&lt;00:00, 92.4MB/s]"
     }
    },
    "b4e581c1ceb9408790f30b96cff73f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58c5855440754107a3706f941d83e0f4",
      "max": 178728960,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5680358c1e74addbddab3e381c36019",
      "value": 178728960
     }
    },
    "b5680358c1e74addbddab3e381c36019": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b69f7c47a904498986d106e1bf36d926": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba09c1085fa74be4a05eced774156f7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d506f02006a648639ab6619118be8db1",
      "placeholder": "​",
      "style": "IPY_MODEL_e4d9fd672c704905a9a13c7d930dbad8",
      "value": " 170M/170M [00:04&lt;00:00, 44.4MB/s]"
     }
    },
    "bf9892dfa56c4cd6ae37fb8318044378": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d506f02006a648639ab6619118be8db1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4d9fd672c704905a9a13c7d930dbad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e91dacd227004bfbb066cd835e22afd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f8ff8022dae4990b1ea432b2e9d3c07",
       "IPY_MODEL_92a04383007146e9b74ad6b15bc80413"
      ],
      "layout": "IPY_MODEL_8560f77e7d414d4ba09d847a451df0e0"
     }
    },
    "f0858d6174ed4af7b49a103e61536b04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
